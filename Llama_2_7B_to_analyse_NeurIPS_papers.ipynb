{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KGPRxxJKfmn"
      },
      "source": [
        "# **Training Llama 2 7B on NIPS 2015 research papers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIf3Q7QaK4gn"
      },
      "source": [
        "## **Install replicate to run the Llama 2 LLM using an API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGwfwAsLJsSR",
        "outputId": "7a8b358e-ffba-4099-c96f-f77a0a371ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.26.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.1)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.18.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.1)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 replicate-0.26.1\n"
          ]
        }
      ],
      "source": [
        "! pip install replicate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqBzUTg9NMdh"
      },
      "source": [
        "## **Set Replicate API token**\n",
        "https://replicate.com/account/api-tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ga2m-1FNP7o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSdl64RIBZt5"
      },
      "source": [
        "# **Testing chatbot text generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7Zy75BMBYQi",
        "outputId": "4e8b4c1b-01d0-4620-8f1d-aebf46c8c9f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hello! I'm here to help you with any questions you may have. A llama is a domesticated South American mammal that is closely related to the alpaca. Llamas are known for their distinctive long necks, ears, and soft, woolly coats. They are often used as pack animals in the Andes region, where they originated, and are also kept as pets in many parts of the world. Is there anything else I can help you with?"
          ]
        }
      ],
      "source": [
        "import replicate\n",
        "\n",
        "# Prompts\n",
        "pre_prompt = \"You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'.\" #Tells LLM what it should be\n",
        "prompt_input = \"What is a llama?\" #LLM generates output based on this prompt\n",
        "\n",
        "\n",
        "input = {\n",
        "    \"top_p\": 0.1,\n",
        "    \"prompt\": f\"{pre_prompt} {prompt_input} Assistant: \",\n",
        "    \"temperature\": 0.1,\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"min_new_tokens\": -1\n",
        "}\n",
        "\n",
        "\n",
        "for event in replicate.stream(\n",
        "    \"meta/llama-2-7b-chat\",\n",
        "    input=input\n",
        "):\n",
        "    print(event, end=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4gDpTbxTago"
      },
      "source": [
        "# **Using Kaggle NIPS 2015 Papers dataset for training**\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/benhamner/nips-2015-papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tkwrj5lTf3z",
        "outputId": "1769b33c-6234-44e5-fa74-e63b175197af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0UyPNG-Tk2Q"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlvYThWiyeWR"
      },
      "source": [
        "kaggle.json uploaded to this colab notebook to access Kaggle api\n",
        "https://www.kaggle.com/settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF25h5lCTmdq"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP2Sbq1DTsRG"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTB3xjTxTz89",
        "outputId": "554b85c9-096d-4dab-da84-cc10ba513696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/benhamner/nips-2015-papers\n",
            "License(s): ODbL-1.0\n",
            "Downloading nips-2015-papers.zip to /content\n",
            " 72% 7.00M/9.67M [00:01<00:00, 10.1MB/s]\n",
            "100% 9.67M/9.67M [00:01<00:00, 7.94MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download benhamner/nips-2015-papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhmLcohCUp6O",
        "outputId": "063522c9-0575-4e3f-bbb2-0938c0affd0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  nips-2015-papers.zip\n",
            "  inflating: Authors.csv             \n",
            "  inflating: PaperAuthors.csv        \n",
            "  inflating: Papers.csv              \n",
            "  inflating: accepted_papers.html    \n",
            "  inflating: database.sqlite         \n",
            "  inflating: hashes.txt              \n"
          ]
        }
      ],
      "source": [
        "! unzip nips-2015-papers.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5kgs-uiVRHG"
      },
      "source": [
        "Papers.csv will be used to train Llama 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UTVt0PMWp5t"
      },
      "source": [
        "# **Using Langchain and Pinecone to process dataset so that Llama can be trained on the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R10plHTYZ9dt",
        "outputId": "1d0da1d3-b9b1-4a68-c745-cb9a94753a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.2.9)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.6.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain langchain-community langchain-core pinecone transformers sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YExQRaHcpAs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pinecone\n",
        "import sys\n",
        "from langchain.llms import Replicate\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders.csv_loader import CSVLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMbMtcUic4Cy"
      },
      "source": [
        "Initialize Pinecone with API Key and Environment\n",
        "\n",
        "https://app.pinecone.io/organizations/-O0DMW8sX5mY9OFiqyhh/projects/650d4fd9-8428-4461-b248-bdbf8e44edb7/keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz3Bu1HUc4Zw"
      },
      "outputs": [],
      "source": [
        "# pc = Pinecone(api_key=\"\")\n",
        "# index = pc.Index(\"llama2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBcXV9dCd3kR"
      },
      "source": [
        "Load csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNfarYZULbga"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Papers.csv')\n",
        "\n",
        "# editing data frame\n",
        "df = df.head(5)\n",
        "\n",
        "# after editing file yo can save it to as a csv file\n",
        "df.to_csv('Papers.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li3qgiLbd4nw"
      },
      "outputs": [],
      "source": [
        "loader = CSVLoader(file_path=\"./Papers.csv\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcEbeqOXeDiO",
        "outputId": "80186e08-7e41-43bb-d4dc-47e793f089f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1443, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1055, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1889, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3135, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 882, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2931, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1119, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 744, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1724, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 866, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1417, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1586, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2268, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 561, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 635, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2154, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1509, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1260, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1279, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1080, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2041, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 505, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1001, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 513, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 758, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2084, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 544, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2366, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 599, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 789, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1043, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1611, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1079, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 995, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 958, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 978, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 717, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4143, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1425, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1178, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2101, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2592, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1813, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 973, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3301, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1003, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3318, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2820, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1055, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2022, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2383, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1176, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 768, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2800, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1362, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3322, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1415, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 910, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2095, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2654, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 640, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2515, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 574, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1211, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1004, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 513, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 739, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 741, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 867, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 742, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 638, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 867, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 961, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 838, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1128, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 541, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2263, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1251, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 898, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1720, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2034, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 915, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 745, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 636, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2824, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 549, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2992, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 608, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 585, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1098, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1004, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1095, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1498, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 504, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 889, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1118, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3241, which is longer than the specified 500\n"
          ]
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)  #split into smaller chunks\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_BCx472eMIG",
        "outputId": "d91362ed-806c-4946-bc16-c28ce8668531"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGc1w81geYU_"
      },
      "source": [
        "Pinecone Index for Storing Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7mwfJoTfNxO",
        "outputId": "b23cdca9-e9c3-4f7e-a034-204b87a75f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-4.1.1-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.6.2)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.9)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-client\n",
            "Successfully installed pinecone-client-4.1.1 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install -U pinecone-client langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24eYYQUDfrrs",
        "outputId": "bbebb228-cb78-4261-d999-0a8156741983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-pinecone\n",
            "  Downloading langchain_pinecone-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (0.2.9)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (1.25.2)\n",
            "Collecting pinecone-client<4.0.0,>=3.2.2 (from langchain-pinecone)\n",
            "  Downloading pinecone_client-3.2.2-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.9/215.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (0.1.82)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.7.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-pinecone) (8.4.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain-pinecone) (2024.6.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain-pinecone) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain-pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain-pinecone) (2.0.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-pinecone) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-pinecone) (3.7)\n",
            "Installing collected packages: pinecone-client, langchain-pinecone\n",
            "  Attempting uninstall: pinecone-client\n",
            "    Found existing installation: pinecone-client 4.1.1\n",
            "    Uninstalling pinecone-client-4.1.1:\n",
            "      Successfully uninstalled pinecone-client-4.1.1\n",
            "Successfully installed langchain-pinecone-0.1.1 pinecone-client-3.2.2\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade langchain-pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzrvJpb61NdF"
      },
      "source": [
        "Set Pinecone API Key\n",
        "\n",
        "https://app.pinecone.io/organizations/-O0DMW8sX5mY9OFiqyhh/projects/650d4fd9-8428-4461-b248-bdbf8e44edb7/keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjS8DYbYeYm3"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "os.environ['PINECONE_API_KEY'] = ''\n",
        "vectordb = PineconeVectorStore.from_documents(texts, embeddings, index_name=\"llama2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGd4c6LaFKcC"
      },
      "source": [
        "# **Training Llama 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wWxlaMUFVKl",
        "outputId": "4d2f9ed2-f605-40dd-9ceb-6a3f87bb5ca0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.llms.replicate:Init param `input` is deprecated, please use `model_kwargs` instead.\n"
          ]
        }
      ],
      "source": [
        "llm = Replicate(\n",
        "    model=\"a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5\",\n",
        "    input={\"temperature\": 0.1, \"max_length\": 1000}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTkgil6XgbQQ"
      },
      "outputs": [],
      "source": [
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    vectordb.as_retriever(search_kwargs={'k': 2}),\n",
        "    return_source_documents=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrT0YOiOTrD4"
      },
      "source": [
        "# **Llama 2 has now been trained on the dataset, and we can ask it questions about the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlXr-_wJggvq",
        "outputId": "fd57d98f-5665-47e4-96e9-af73be97cd5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hello! I'd be happy to help you with information about the dataset you provided.\n",
            "\n",
            "Based on the information in the table and figure, this appears to be a synthetic dataset with six columns of data. The first column is labeled \"Noise Rate,\" and the remaining five columns are labeled \"01 Error.\" The table shows the mean and standard deviation of the 01 error over 125 trials on LS10, with grayed cells indicating the best performer at each noise rate.\n",
            "\n",
            "From the figure, it seems that the dataset is related to the LS10 dataset, which is a benchmark dataset for image denoising tasks. The figure shows a plot of the 01 error against the noise rate, with the best performer at each noise rate indicated by the grayed cells in the table.\n",
            "\n",
            "Without more information about the context and purpose of the dataset, it's difficult to provide more specific information or insights about the data. However, I'm happy to help answer any follow-up questions you may have based on the information provided.\n"
          ]
        }
      ],
      "source": [
        "chat_history = []\n",
        "query = \"Tell me about this dataset\"\n",
        "result = qa_chain({'question': query, 'chat_history': chat_history})\n",
        "print(result['answer'])\n",
        "chat_history.append((query, result['answer']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
